{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Improving the way neural networks learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The techniques we'll develop in this chapter inculde: a better choice of cost function, known as the cross-entropy cost function; four so-called \"regularization\" methods (L1 and L2 regularization, dropout, and artificial expansion of the training data), which make our networks better at generalizing beyond the training data; a better method for initializing the weights in the network; and a set of heuristics to help choose good hyper-parameters for the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we're only covering a few of the many, many techniques which have been developed for use in neural nets. **The philosophy is that the best entree to the plethora of available techniques is in-depth study of a few of the most important. Mastering those important techniques is not just useful in its own right, but will also deepen your understanding of what problems can arise when you use neural networks. That will leave you well prepared to quickly pick up other techniques, as you need them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - The cross-entropy cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in last chapter (section 2.4), a weight will learn slowly if either the input neuron is low-activation($a^{l-1}_k\\approx0$),or if the output neuron has saturated, i.e., is either high- or low-activation. This is the origin of the learning slowdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Introducing the cross-entropy cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we address the learning slowdown? It turns out that we can solve the problem by replacing the quadratic cost with a different cost function, known as the cross-entropy. You may doubt about this. It's intuitively that we should replace the activation function $\\sigma$ with another activation function instead of replacing the quadratic cost. You will undertand this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the cross-entropy cost function by\n",
    "\n",
    "$$C = -\\frac{1}{n}\\sum_{x}[y\\;lna + (1-y)ln(1-a)], \\tag{3.1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where n is the total number of items of training data, the sum is over all training inputs, $x$, and $y$ is the corresponding desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not obvious that the expression (3.1) fixes the learning slowdown problem. In fact, frankly, it's not even obvious that it makes sense to call this a cost function! However, it's a good news that the Equation (3.1) satisfies the two assumptions of backpropagation algorithm in last chapter (section 2.2). Before addressing the learning slowdown, let's see in what sense the cross-entropy can be interpreted as a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two properties in particular make it reasonable to interpret the cross-entropy as a cost function.\n",
    "\n",
    "* Non-negative\n",
    "* If the neuron's actual output is close to the desired output, then the cross-entropy will be close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are both properties we'd intuitively expect for a cost function.** So that's good news for the cross-entropy, and we understand why call cross-entropy a cost function. Then we address the problem of learning slowdown. To see this, let's compute the partial derivative of the cross-entropy cost with respect to the weights. We substitute $a = \\sigma(z)$ into (3.1), and apply the chain rule twice, obtaining:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial w_j} = -\\frac{1}{n}\\sum_{x}(\\frac{y}{\\sigma(z)} - \\frac{1-y}{1-\\sigma(z)})\\sigma'(z)x_j =\\frac{1}{n}\\sum_{x}\\frac{\\sigma'(z)x_j}{\\sigma(z)(1-\\sigma(z))}(\\sigma(z) - y). \\tag{3.2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $\\sigma'(z) = \\sigma(z)(1-\\sigma(z))$, and it simplifies to become:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial w_j} = \\frac{1}{n}\\sum_{x}x_j(\\sigma(z) - y). \\tag{3.3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a beautiful expression. It tells us that the rate at which the weight learns is controlled by $\\sigma(z)-y$. The larger the error, the faster the neuron will learn. This is just what we'd intuitively expect. **In particular, it avoids the learning slowdown caused by the $\\sigma'(z)$ term. When we use the cross-entropy, the $\\sigma'(z)$ term gets canceled out, and we no longer need worry about it being small.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way, we can compute the partial derivative for the bias. I won't go through all the details again, but you can easily verify that\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial b} = \\frac{1}{n}\\sum_{x}(\\sigma(z) - y). \\tag{3.4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this avoids the learning slowdown caused by the $\\sigma'(z)$ term."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
