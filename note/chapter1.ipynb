{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this book is about?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This book introduces one of the most beautiful programming paradigms so-called neural networks. In the conventional approach to programming, **we tell the computer what to do**. By contrast, in a neural network we don't tell the computer how to solve our problem. Instead, **it learns from observational data**, **figuring out its own solution to the problem**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this book is to **help you master the core concepts of neural networks**. One conviction underlying the book is that **it's better to obtain a solid understanding of the core principles of neural networks and deep learning**, rather than a hazy understanding of a long laundry list of ideas. If you have understood the core ideas well, you can rapidly understand other new material. **You need to understand the durable, lasting insights underlying how neural networks work.**\n",
    "\n",
    "**Technologies come and go, but insight is forever.**\n",
    "\n",
    "You will learn the core principles behind neural networks and deep learning by attacking a concrete problem: the problem of teaching a computer to recongnize handwritten digits. This book will not only include abstract theory but also living code, and you will understand the fundamentals **both in theory and practice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Using nerual nets to recognize handwritten digits\n",
    "## 1.1 - Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptrons are a type of artificial neuron. Though today it is more common to use other models of artificial neurons on neural networks, and the main neuron model used is one called $sigmoid\\;neuron$. But to understand why sigmoid neurons are defined the way they are, it is worth taking time to first understand perceptrons.\n",
    "\n",
    "A perceptron takes several binary inputs,$x_1$,$x_2$,..., and produces a single binary output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perceptron](../picture/chapter1/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input with a corresponding $weight$ to compute the output. The weights are real numbers represent the importance of the respective inputs to the output. The larger value of $w_1$ indicates that the input $x_1$ is more important. The neuron's output, 0 or 1, is determined by whether the weighted sum $\\sum_j w_jx_j$ is less than or greater than some $threshold\\;value$. Just like the weights, the threshold is a real number which is a parameter of the neuron. To put it in more precise algebraic terms:\n",
    "![perceptron](../picture/chapter1/p2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make two notational changes to simplify this description. The first change if to write $\\sum_j w_jx_j$ as a dot product, $w\\cdot x = \\sum_j w_jx_j$, where $w$ and $x$ are **vectors** whose components are the weights and inputs respectively. The second change is to remove the threshold to the other side of the inequality and to replace it by $bias$, $b \\equiv -threshold$. So bias can be consider as a measure of how easy it is to get the perceptron to output a 1. Then the preceptron rule can be rewritten:\n",
    "![perceptron](../picture/chapter1/p3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use perceptrons to both make decisions and compute the elementary logical functions such as AND, OR, and NAND. \n",
    "\n",
    "Let $x_1$, $x_2$,..., represent the evidence of a decision respectively and $w_1$, $w_2$,..., indicate the importance of corresponding evidence. Finally, you should only define the $bias$ and the value of the $bias$ means how desirable you want to make that decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following perceptron has two inputs, each with weight -2, and an overall bias of 3 like:\n",
    "![perceptron](../picture/chapter1/p4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we see that input 00 produces output 1, since (-2)x0 + (-2)x0 + 3 = 3 is positive. Similar calculations show that the inputs 01 and 10 produce output 1. But the input 11 produces output 0, since (-2)x1 + (-2)x1 + 3 = -1 is negative. And so our perceptron implements a NAND gate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Becasue the NAND gate is universal for computation, that is, we can build any computation up out of NAND gate, so we can use networks of perceptrons to compute any logical function at all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 Sigmoid neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should know little about how neurons work in neural networks before introduce this artificial neuron. It turns out that we can devise learning algorithms which can automatically tune the weights and biases of a network of artificial neurons so that the output of network is our desired result. To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the network. Here is what we want:\n",
    "![sigmoid](../picture/chapter1/p5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it were true that a small change in a weight (or bias) causes only a small change in output, then we could use this fact to modify the weights and biases to get our network to behave more in the manner we want. The problem is that this isn't what happens when our network contains perceptrons. **In fact, a small change in the weights or bias of any single perceptron in the network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1**. **That flip may then cause the behaviour of the rest of the network to completely change in some very complicated way.** So this makes perceptrons hard to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can overcome this problem by introducing a new type of artificial neuron called a $sigmoid\\;neuron$. **Sigmoid neurons are similar to perceptrons, but modified so that small changes in their weights and bias cause only a small change in their output.** That is the crucial fact which we allow a network of sigmoid neurons to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed before, sigmoid neurons are similar to perceptrons: \n",
    "\n",
    "![sigmoid](../picture/chapter1/p6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sigmoid neuron has inputs, $x_1$, $x_2$,....**But instead of being just 0 or 1, these inputs can also take on any values between 0 and 1**. Also just like a perceptron, the sigmoid neuron has weights for each input, $w_1$, $w_2$,..., and an overall bias, b. **But the output is not 0 or 1**. Instead, it's $\\sigma(wx + b)$, where $\\sigma$ is called sigmoid function, and is defined by:\n",
    "\n",
    "$$\\sigma(z)\\equiv \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it all a little more explicitly, the output of a sigmoid neuron with inputs $x_1$,$x_2$,...,weights $w_1$,$w_2$,..., and bias b is\n",
    "\n",
    "$$\\frac{1}{1 + exp\\;(-\\sum_j w_jx_j - b\\;)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image of sigmoid function is as follows:\n",
    "\n",
    "![sigmoid](../picture/chapter1/p7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many similarities between perceptrons and sigmoid neurons. To understand the similarities, we define $z\\equiv w\\cdot x+b$ and conclude that \n",
    "\n",
    "$$\\lim_{z \\to +\\infty} \\sigma(z) = 1\\;and\\;\\lim_{z \\to -\\infty} \\sigma(z) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If z is a large postive number, then the output of a single perceptron is 1. And if z is very negative, then the output is 0. Perceptrons and sigmoid neurons are completely same in both respects. **Indeed, it is the smoothness of $\\sigma$ function that is crucial fact.** The smoothness of $\\sigma$ means that small changes $\\Delta w_j$ in the weights and $\\Delta b$ in the bias will produce a small change $\\Delta output$ in the ouput from the neuron. Infact, calculus tells us that $\\Delta output$ is well approximated by\n",
    "\n",
    "$$\\Delta output \\approx \\sum_{j} \\frac{\\partial \\, output}{\\partial \\, w_j} \\Delta w_j + \\frac{\\partial \\, output}{\\partial b} \\Delta b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually saying something very simple and exactly a good news: $\\Delta output$ is a linear function of the changes $\\Delta w_j$ and $\\Delta b$ in the weights and bias. **This linearity makes it easy to choose small changes in the weights and biases to achieve any desired small change change in the output.** One thing we should notice is that the output of a single sigmoid neuron is also a real number between 0 and 1, which is different from the output of perceptrons. However, this property is very useful when our desired classification of results are more than two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 The architecture of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we introduce some terms of neural networks. Suppose we have the network:\n",
    "\n",
    "![architecture](../picture/chapter1/p8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, the leftmost layer in this network is called the input layer and the rightmost layer is called output layer. The middle layer is called $hidden\\;layer$, and this network has two hidden layers. **For historical reasons, such multiple layer networks are sometimes called `multilayer perceptrons` or `MLPs`, despite being make up of sigmoid neurons, not perceptrons**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two architectures of neural networks called $feedforward\\ neural\\ networks$ and $recurrent\\ neural\\ networks$. The former neural networks where the output from one layer is used as input to the next layer ans this means there are no loops in the network. Instead, there are feedback loops in the latter. The idea in these models is to have neurons which fire for some limited duration of time, before becoming quiescent. **Loops don't cause problems in such a model, since a neuron's output only affects its input at some later time, not instantaneously.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4 A simple network to classify handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of recognizing handwritten digits can be splitted into two sub-problems:\n",
    "* Breaking an image containing many digits into a sequence of separate images, each containing a single digit.\n",
    "* Classifying each individual digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on writing a program to solve the second problem. To recognize individual digits we will use a three-layer neural network:\n",
    "\n",
    "![network](../picture/chapter1/p9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input layer contains neurons encoding the valus of the input pixels. Because our training data consist of many 28 by 28 pixel images of scanned handwritten digits, so the input layer contains 784 = 28 x 28 neurons. The input pixels are greyscale, with a value of 0.0 representing white, a value of 1.0 representing black, and in between values representing gradually darkening shades of grey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer of the network is hidden layer which contains $n = 15$ neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most discussed layer here must be the output layer.** The output layer of the network contains 10 neurons. We number the output neurons from 0 through 9, and figure out which neuron has the highest activation value. For example, if that neuron number is 6, then our network will guess that input digit was a 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is a interesting problem that why we use 10 output neurons.** A seemingly natural way of doing that is to use just 4 output neurons, treating each neuron as taking on a binary value, depending on whether the neuron's output is closer to 0 or to 1. **Four neurons are enough to encode the answer, since $2^4 = 16$ is more than the 10 possible values for the input digit.** Why should our network use 10 neurons instead?\n",
    "\n",
    "A little convinced reason is that there's no easy way to relate that most significant bit to simple shapes. And it's hard to imagine that there's any good historical reason the component shapes of the digit will be closely related to the most significant bit in the output. **This sounds emprically, but neuron networks are so sophisticated that we cann't confirm this doesn't work for other problems.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5 Learning with gradient descent\n",
    "### Dataset\n",
    "The dataset we will use is so-called MNIST, which contains tens of thousands of scanned images of handwritten digits, together with their correct classifications. The MNIST data comes in two parts. The first part contains 60,000 images to be used as training data. And the second part of the MNIST data set is 10,000 images to be used as test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "Our cost function is defined by:\n",
    "$$C(w,b)\\equiv \\frac{1}{2n} \\sum_{x}\\|y(x) - a\\|^2 \\tag{1.1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, n is the total number of training inputs(and should we change n when we augment the training data?).** So the aim of our training algorithm will be to minimize the cost C(w,b) as a function of the weights and biases. In other words, we want to find a set of weights and biases which make the cost as small as possible. We'll do that using an algorithm known as $gradient\\ descent$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why introduce the quadratic cost? After all, aren't we primarily interested in the number of images correctly classified by the network? Why not try to maximize that number directly, rather than minimizing a proxy measure like the quadratic cost(Maybe one reason is that making small changes to the weights and biases won't cause any change at all in the number of training images classified correctly)?** Attention should be paied to these questions due to there are some papers pose new algorithms that contribute direct to the number of images correctly classified instead of any quadratic cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks to the technique so-called gradient descent and the quadratic cost is a smooth multi-function of all the weights and biases in the network, we can make small changes in the weights and biases so as to get an improvement in the cost. So can we design a function that we can optimize it so as to get an improvement in the number of images correctly classified directly?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's come back to the gradient descent which contributes to minimize the cost $C(w,b)$ as a function of the weights and biases. So for now we're going to forget all about the specific form of the cost function, the connection to neural networks, and so on. **Instead, we'are going to images that we're simply been given a function of many variables and we want to minimize that function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gain insight by imagining $C$ as a function of just two variables and later we will extend it into more variabes. We start by thinking of our function as a kind of a valley(the geometric interpretation of the binary function). **We'd randomly choose a starting point for an ball, and then simulate the motion of the ball as it rolled down to the bottom of the vally which is the global minimum of $C$.** To make this question more precise, let's think about what happens when we move the ball a small amount $\\Delta v_1$ in the $v_1$ direction, and a small amount $\\Delta v_2$ in the $v_2$ direction. Calculus tells us that $C$ changes as follows:\n",
    "\n",
    "$$\\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 + \\frac{\\partial C}{\\partial v_2} \\Delta v_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We're going to find a way of choosing $\\Delta v_1$ and $\\Delta v_2$ so as to make $\\Delta C$ negative.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It hepls to define $\\Delta v$ to be the vector of changes in $v$, $\\Delta v \\equiv(\\Delta v_1, \\Delta v_2)^T$, and $\\triangledown C$ to be the vector of partial derivatives, $(\\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2})^T$. With these definitions, the expression for $\\Delta C$ can be rewritten as\n",
    "$$\\Delta C \\approx \\triangledown C \\cdot \\Delta v \\tag{1.2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This equation lets us see how to choose $\\Delta v$ so as to make $\\Delta C$ negative.** In particular, suppose we choose\n",
    "\n",
    "$$\\Delta v = -\\eta\\triangledown C,$$\n",
    "\n",
    "where $\\eta$ is a small, positive parameter (known as the $learning\\ rate$). Then $\\Delta C \\approx -\\eta\\triangledown C\\cdot\\triangledown C=-\\eta\\|\\triangledown C\\|^2$. Becuase $|\\triangledown C\\|^2 \\ge 0$, this guarantees that $\\Delta C \\le 0$. We will compute a value for $\\Delta v$, then move the ball's position $v$ by that amount:\n",
    "\n",
    "$$\\Delta v = v' - v \\; \\rightarrow \\;  v' = v + \\Delta v ,$$\n",
    "\n",
    "$$v \\; \\rightarrow \\; v' = v + \\Delta v = v - \\eta\\triangledown C$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summing up, the way the gradient descent algorithm works is to repeatedly compute the gradient $\\triangledown C$, and then to move in the opposite direction, \"falling down\" the slope of the valley.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make gradient descent work correctly, we need to choose the learning rate $\\eta$ to be small enough that Equation 1.2 is a good approximation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indeed, gradient descent is the optimal strategy for searching for a minimum.** One reason can be available from [here](https://github.com/fuqianya/neural-networks-and-deep-learning/blob/master/exercise/chapter1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying gradient descent to learn in a neural network by replacing the variables $v_j$ with the weights and biases. And the gradient vector $\\triangledown C$ has corresponding components $\\partial C\\,/\\,\\partial w_k$ and  $\\partial C\\,/\\,\\partial b_l$. Writing out the gradient descent update rule in terms of components, we have\n",
    "\n",
    "$$w_k\\;\\;\\;\\rightarrow \\;\\;\\;w'_k = w_k - \\eta \\frac{\\partial C}{\\partial w_k}$$\n",
    "\n",
    "$$b_l\\;\\;\\;\\rightarrow \\;\\;\\;b'_l = b_l - \\eta \\frac{\\partial C}{\\partial b_l} .$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of challenges in applying the gradient descent rule. One of the problems is that how to compute the $\\triangledown C$ efficiently. **To understand what the problem is, let's look back at the quadratic cost. Notice that this cost function has the form $C = \\frac{1}{n}\\sum_x C_x$, that is, it's an average over costs $C_x \\equiv \\frac{\\|y(x) - a\\|^2}{2}$ for individual training examples.** Unfortunately, when the number of training inputs is very large this can take a long time, and learning thus occurs slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea called $stochastic\\ gradient\\ descent$ can be used to speed up learning. **The idea is to estimate the gradient $\\triangledown C$ by computing  $\\triangledown C_x$ for a small sample of randomly chosen training inputs(mini-batch).** Provided the sample size $m$ is large enough we expect that the average value of the $\\triangledown C_{X_j}$ will be roughly equal to the average over all $\\triangledown C_x$, that is,\n",
    "\n",
    "$$\\frac{\\sum_{j=1}^{m} \\triangledown C_{X_j}}{m} \\approx \\frac{\\sum_{x} \\triangledown C_x}{n} = \\triangledown C ,\\tag{1.3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the second sum is over the entire set of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's worth noting that in Equation 1.1 we scaled the overall cost function by a factor $\\frac{1}{n}$(Here n can not be replaced by $m$).** People sometimes omit the $\\frac{1}{n}$, summing over the costs of individual training examples instead of averaging. **This is particularly useful when the total number of training examples isn't known in advance. This can occur if more training data is being generated in real time(e.g. data augment).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, in a similar way, the mini-batch update rules 1.3 sometimes omit the $\\frac{1}{m}$ term out the front of the sums. **Conceptually this makes little difference, since it's equivalent to rescaling the learning rate $\\eta$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of stochastic gradient descent as being like political polling: it's much easier to sample a small mini-batch than it is to apply gradient descent to the full batch. **Of course, the estimate won't be perfect - there will be statistical fluctuations - but it doesn't need to be perfect: all we really care about is moving in a general direction that will help decrease C.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
